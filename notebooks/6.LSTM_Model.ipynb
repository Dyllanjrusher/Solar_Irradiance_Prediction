{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext\n",
    "from bigdl.util.common import *\n",
    "\n",
    "\n",
    "# create sparkcontext with bigdl configuration\n",
    "sc = SparkContext.getOrCreate(conf=create_spark_conf().setMaster(\"local[*]\"))\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sparkContext = sc)\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "batch_size = 10\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "df = spark.read.csv(f\"hdfs://localhost:9000/solar_data/processed/Arkansas_1.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "cols.remove('year')\n",
    "cols.remove('month')\n",
    "cols.remove('day')\n",
    "cols.remove('sum(GHI)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = df.select('sum(GHI)')\n",
    "Xs = df.select(cols)\n",
    "\n",
    "#converting to rdd\n",
    "rddys = ys.rdd.map(list)\n",
    "rddXs = Xs.rdd.map(list)\n",
    "\n",
    "X_train, X_test = rddXs.randomSplit([.8, .2])\n",
    "y_train, y_test = rddys.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rddXs.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_size, hidden_size, output_size):\n",
    "    model = Sequential()\n",
    "    recurrent = Recurrent()\n",
    "    recurrent.add(LSTM(input_size, hidden_size))\n",
    "    model.add(InferReshape([-1, input_size], True))\n",
    "    model.add(recurrent)\n",
    "    model.add(Select(2, -1))\n",
    "    model.add(Linear(hidden_size, output_size))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createSequential\n",
      "creating: createRecurrent\n",
      "creating: createTanh\n",
      "creating: createSigmoid\n",
      "creating: createLSTM\n",
      "creating: createInferReshape\n",
      "creating: createSelect\n",
      "creating: createLinear\n"
     ]
    }
   ],
   "source": [
    "model = build_model(168,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createMSECriterion\n",
      "creating: createDefault\n",
      "creating: createSGD\n",
      "creating: createMaxEpoch\n",
      "creating: createDistriOptimizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyllanjr/anaconda3/envs/solarenv/lib/python3.6/site-packages/bigdl/optim/optimizer.py:864: UserWarning: You are recommended to use `create` method to create an optimizer.\n",
      "  warnings.warn(\"You are recommended to use `create` method to create an optimizer.\")\n"
     ]
    }
   ],
   "source": [
    "# Create an Optimizer\n",
    "optimizer = Optimizer(\n",
    "    model=model,\n",
    "    training_rdd=X_train,\n",
    "    criterion=MSECriterion(),\n",
    "    optim_method=SGD(learningrate=learning_rate),\n",
    "    end_trigger=MaxEpoch(training_epochs),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c8742d3f054d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcurr_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object does not support indexing"
     ]
    }
   ],
   "source": [
    "#Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "prediction_seqs = []\n",
    "data = X_test\n",
    "prediction_len = 1\n",
    "window_size=1\n",
    "for i in range(data.count()//prediction_len):\n",
    "    curr_frame = data[i*int(prediction_len)]\n",
    "    predicted = []\n",
    "    for j in range(int(prediction_len)):\n",
    "\n",
    "        curr_data = curr_frame[np.newaxis,:,:]\n",
    "\n",
    "        curr_data_rdd = sc.parallelize(curr_data).map(lambda x: Sample.from_ndarray(x,[0]))\n",
    "\n",
    "        preds = model.predict(curr_data_rdd).collect()[0][0][0]\n",
    "        predicted.append(preds)\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "predictions = prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
